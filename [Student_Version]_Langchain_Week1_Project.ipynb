{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/foopoiuyt/uplimit/blob/main/%5BStudent_Version%5D_Langchain_Week1_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-T0u92GVJE6"
      },
      "source": [
        "This notebook is part of the course: [LLM Apps with Langchain](https://uplimit.com/course/llm-apps-with-langchain) and is created by Sidharth Ramachandran as the project for Week 1 of the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmgRqB0z3JLd"
      },
      "source": [
        "# Let's build \"PillPal\" - a Telegram bot and website that allows users to ask questions based on the Patient Information Leaflet (PIL) or drug guide that comes with any medication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcmYA3M8aGp3"
      },
      "source": [
        "![Package Information Leaflet](https://i.ibb.co/ZSdGyjV/ima-image-36904.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ-FEcb8SjNy"
      },
      "source": [
        "I'm sure you have all come across the thin piece of folded paper that is part of every drug prescription box. Usually the text is in very small print and typically provides information about dosages, side effects, storage instructions and much more. They are hard to read and understand and requires some effort to get answers to common questions a patient might have. What if we could create a product that answers these questions and actually makes the medical information more accessible and easier to understand - enter PillPal!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fEvG823VR9F"
      },
      "source": [
        "In the process of building PillPal, we will go through the following stages and on the way learn more about LLM Apps and their typical life-cycle.\n",
        "\n",
        "1. BUILD the app: this is where we first test the idea, try multiple options for various parts of the pipeline till we are satisfied to a reasonable extent that the product works.\n",
        "2. DEPLOY & MONITOR the app: this is where we want to make the app available to our first users, monitor it's behaviour and discover edge cases.\n",
        "3. EVALUATE & IMPROVE the app: this is the final and ongoing stage where we will build an evaluation suite that constantly checks whether our app is working as expected and perform experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2S69-R7aK0k"
      },
      "source": [
        "We will use Langchain to develop the app, deploy it as a Telegram bot/ Website and use Langsmith to monitor, evaluate and improve the product. Please consider PillPal as the chosen example/ case study to illustrate the process but feel free to adapt this project ot build any app of your choice!\n",
        "\n",
        "# # üë®‚Äçüéì Learner Project\n",
        "\n",
        "In the project walkthrough session we will go through the various steps of the project with an example of one of the drugs. The learner project is to implement the same steps for a different drug OR any other PDF of your choice. Concretely, here are steps that you need to do:\n",
        "\n",
        "1. Identify a PDF that you would like to ask questions about. Suggestion: choose another drug or medication that you are familiar with.\n",
        "2. Upload and use that PDF as you go through this notebook.\n",
        "3. Make use of the sections and flow as a guide but you are expected to update and write code to complete the RAG project for your PDF.\n",
        "4. Feel free to adapt any sections to add more functionality or adapt for your use case/ PDF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruybS1MUZ3--"
      },
      "source": [
        "# Step 0: Necessary libraries and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JbQIsr6r6kOq",
        "outputId": "20793866-b6e1-40ae-faf8-c1e5125bffa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.35)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.35)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.3)\n",
            "Requirement already satisfied: grandalf in /usr/local/lib/python3.11/dist-packages (0.8)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.2.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.16.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary libraries to get it out of the way\n",
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install langchain-openai\n",
        "!pip install faiss-cpu\n",
        "!pip install pymupdf\n",
        "!pip install grandalf\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WeuJlFzdOnBA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['LANGSMITH_TRACING'] = 'true'\n",
        "os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
        "os.environ['LANGSMITH_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ['LANGSMITH_PROJECT'] = \"pr-indelible-manservant-54\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kCSk1SucCyS"
      },
      "source": [
        "### OpenAI Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SmzMEqgcFg2"
      },
      "source": [
        "You will be provided an API key by the Course Manager. If you are not able to find it, please reach out on ask for help on the Discussion forums.\n",
        "\n",
        "Please note that this is a shared API key for the entire class, so please make sure to use it responsibly. We will also show you steps below to add it to your secret keys so that it is not revealed in any way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R3CUqKij-mo"
      },
      "source": [
        "Once you have obtained the API key, you can add it to the Google Colab instance by adding it to the Secrets section as shown below. Please use the variable name 'OPENAI_API_KEY' and paste the value that you copied before.\n",
        "\n",
        "![Add to Google Colab](https://i.ibb.co/Cb57Sxq/Xnapper-2024-06-09-21-42-30.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS1dSf8E6ZUS"
      },
      "source": [
        "# Step 1: Building the PillPal bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0It6mAFmW4Qj"
      },
      "source": [
        "The patient information leaflets/ drug booklets are typically available in the form of PDFs from the drug manufacturers website or from a central repository like in the [UK](https://www.medicines.org.uk/) or the [US](https://dailymed.nlm.nih.gov/). While you should be able to find them relatively easily through an Internet Search, we also include the medical booklet PDFs for two drugs with this code repository to use in the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXAlB_g8ZGM6"
      },
      "source": [
        "One of the best aspects of using Langchain is that it provides a lot of in-built integrations for most common development tasks while building LLM apps. We will make use of several of them during this project, starting with the PDF loader which we will use to read in the medical booklet PDF file. For this example, we have chosen the PIL for Ozempic - a new drug that decreses the risk of heart disease in overweight patients but has been in the news recently for also being a weight loss solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtqgnSjFZ7RP"
      },
      "source": [
        "As we are still in the notebook environment - please follow the below steps to upload the PDF document into the Colab environment.\n",
        "\n",
        "![Upload PDF](https://i.ibb.co/jgDBwY4/Xnapper-2024-06-09-21-58-08.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S505i8I5MbI2"
      },
      "source": [
        "## üìù Learner Task:\n",
        "\n",
        "In the following section, you have to load in your PDF using any of the document loaders available from the Langchain Community package. For example: you could use the `PyMuPDFLoader` for managing PDFs.\n",
        "\n",
        "Your code should do the following:\n",
        "- Load the PDF\n",
        "- Identify the number of pages\n",
        "- Print one of the pages with the associated metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2nJ6tyN7758",
        "outputId": "a2692f42-93d8-488d-af24-6b78a3655eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Document(metadata={'producer': 'Aspose.PDF for .NET 18.7', 'creator': 'Aspose Ltd.', 'creationdate': '2024-07-15T12:29:34+05:30', 'source': './sample_data/timolol.pdf', 'file_path': './sample_data/timolol.pdf', 'total_pages': 10, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-30T17:21:33+05:30', 'trapped': '', 'modDate': \"D:20240730172133+05'30'\", 'creationDate': \"D:20240715122934+05'30'\", 'page': 0}, page_content='PACKAGE LEAFLET: INFORMATION FOR THE USER \\nTimolol 0.25% w/v Eye Drops Solution  \\n(timolol) \\nRead all of this leaflet carefully before you start taking this medicine. because it \\ncontains important information for you. \\n-\\nKeep this leaflet. You may need to read it again.\\n-\\nIf you have any further questions, ask your doctor or pharmacist or nurse.\\n-\\nThis medicine has been prescribed for you only. Do not pass it on to others. It may harm them,\\neven if their signs of illness are the same as yours.\\n-\\nIf you get any side effects, talk to your doctor, pharmacist or nurse. This includes any possible\\nside effects not listed in this leaflet. See section 4.\\nWhat is in this leaflet: \\n1.\\nWhat Timolol is and what it is used for\\n2.\\nWhat you need to know before you use Timolol\\n3.\\nHow to use Timolol\\n4.\\nPossible side effects\\n5.\\nHow to store Timolol\\n6.\\nContents of the pack and other information\\n1.\\nWhat Timolol is and what it is used for\\nTimolol Eye Drops contain a substance called timolol which belongs to a group of medicines called \\nbeta-blockers. Timolol lowers the pressure in your eye(s). It is used to treat glaucoma, when the \\npressure in the eye is raised. \\n2.\\nWhat you need to know before you use Timolol\\nDo not use Timolol Eye Drops if: \\n\\uf0b7\\nyou are allergic (hypersensitive) to timolol , beta-blockers or any of the other ingredients of\\ntimolol (see section 6: Contents of the pack and other information)\\n\\uf0b7\\nyou have now or have had in the past respiratory problems such as asthma, severe chronic\\nobstructive bronchitis (severe lung disease which may cause wheeziness, difficulty in breathing\\nand/or long-standing cough).\\n\\uf0b7\\nyou have heart problems\\n\\uf0b7\\nslow heart beat, heart failure or disorders of heart rhythm (irregular heart beats)\\n\\uf0b7\\nheart failure .\\n-\\n‚Äúcardiogenic shock‚Äù ‚Äì a serious heart condition caused by very low blood pressure, which\\nmay result in the following symptoms: dizziness and lightheadedness, fast pulse rate, white\\nskin, sweating, restlessness, loss of consciousness.\\nIf you are not sure whether you should use Timolol Eye Drops talk to your doctor or pharmacist. \\nWarning and precautions: \\nTalk to your doctor before taking Timolol eye drops if you have now or have had in the past \\n\\uf0b7\\ncoronary heart disease (symptoms can include chest pain or tightness, breathlessness or\\nchoking), heart failure.\\n\\uf0b7\\nlow blood pressure.\\n\\uf0b7\\ndisturbances of heart rate such as slow heart beat.\\n\\uf0b7\\nbreathing problems, asthma or chronic obstructive pulmonary disease')\n",
            "Document(metadata={'producer': 'Aspose.PDF for .NET 18.7', 'creator': 'Aspose Ltd.', 'creationdate': '2024-07-15T12:29:34+05:30', 'source': './sample_data/timolol.pdf', 'file_path': './sample_data/timolol.pdf', 'total_pages': 10, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-30T17:21:33+05:30', 'trapped': '', 'modDate': \"D:20240730172133+05'30'\", 'creationDate': \"D:20240715122934+05'30'\", 'page': 1}, page_content='\\uf0b7 \\npoor blood circulation disease (such as Raynaud‚Äôs disease or Raynaud‚Äôs syndrome) \\n\\uf0b7 \\ndiabetes as Timolol may mask signs and symptoms of low blood sugar \\n\\uf0b7 \\noveractivity of the thyroid gland as Timolol may mask signs and symptoms \\n\\uf0b7 \\nallergies to any medicines \\n\\uf0b7 \\n you wear soft contact lenses. Your eye drops contain a preservative which can be deposited on \\n soft contact lenses. It is important that your lenses are removed before using your eye drops and \\n not put back into your eyes for at least 15 minute. \\n \\nTell your doctor before you have an operation that you are using Timolol Eye Drops as Timolol may \\nchange effects of some medicines used during anaesthesia. \\n \\nIf your eye becomes irritated or any new eye problems come on, talk to your doctor straight away. Eye \\nproblems could include redness of the eye or swelling of the eyelids (see Section 4: Possible Side \\nEffects). \\n \\nIf you suspect that Timolol Eye Drops is causing an allergic reaction or hypersensitivity (for example, \\nskin rash, or redness and itching of the eye), stop using timolol and contact your doctor immediately.  \\n \\nTell your doctor if:  \\n\\uf0b7 \\nyou get an eye infection  \\n\\uf0b7 \\nyou injure your eye or have an operation on it  \\n\\uf0b7 \\nyour eye problems get worse or you get any new symptoms.  \\n \\nChildren and adolescents \\nThere is only very limited data available on the use of timolol in infants and children. For example, in \\none small clinical study, timolol, the active ingredient in Timolol eye drops, has been studied in \\ninfants and children aged 12 days to 5 years, who have elevated pressure in the eye(s) or have been \\ndiagnosed with glaucoma. For more information, talk to your doctor. \\n \\nTimolol should generally be used with caution in young patients. In newborns, infants and younger \\nchildren Timolol should be used with extreme caution. If coughing, wheezing, abnormal breathing or \\nabnormal pauses in breathing (apnoea) occur, the use of the medication should be stopped \\nimmediately. Contact your doctor as soon as possible. A portable apnoea monitor may also be helpful. \\n \\nOther medicines and Timolol Eye drops \\nTimolol Eye Drops can affect or be affected by other medicines you are using, including other eye \\ndrops for the treatment of glaucoma. Tell your doctor if you are using or intend to use medicines to \\nlower blood pressure, heart medicine or medicines to treat diabetes. Please tell your doctor or \\npharmacist if you are taking or have recently taken any other medicines, including other eye drops or \\nmedicines obtained without prescription. \\n \\nIt is important to tell your doctor before using Timolol Eye Drops if you are taking one or more of the \\nfollowing medicines:  \\n \\n\\uf0b7 \\na calcium antagonist, such as nifedipine, verapamil or diltiazem, often used to treat high blood \\npressure, angina, an abnormal heartbeat or Raynaud‚Äôs syndrome  \\n\\uf0b7 \\ndigoxin, a medicine used to relieve heart failure or treat abnormal heartbeat  \\n\\uf0b7 \\nmedicines known as catecholamine-depleting agents, such as rauwolfia alkaloids or reserpine, \\nused for high blood pressure  \\n\\uf0b7 \\nmedicines called pressor amines, such as adrenaline used to treat severe allergic reaction  \\n\\uf0b7 \\nQuinidine (used to treat heart conditions and some types of malaria) \\n\\uf0b7 \\nAntidepressants known as fluoxetine and paroxetine. \\n\\uf0b7 \\nclonidine, a medicine used to treat high blood pressure  \\n\\uf0b7 \\nother beta-blockers taken by mouth or used as eye drops, because they belong to the same group \\nof medicines as Timolol and could have an additive effect.')\n",
            "{'producer': 'Aspose.PDF for .NET 18.7',\n",
            " 'creator': 'Aspose Ltd.',\n",
            " 'creationdate': '2024-07-15T12:29:34+05:30',\n",
            " 'source': './sample_data/timolol.pdf',\n",
            " 'file_path': './sample_data/timolol.pdf',\n",
            " 'total_pages': 10,\n",
            " 'format': 'PDF 1.6',\n",
            " 'title': '',\n",
            " 'author': '',\n",
            " 'subject': '',\n",
            " 'keywords': '',\n",
            " 'moddate': '2024-07-30T17:21:33+05:30',\n",
            " 'trapped': '',\n",
            " 'modDate': \"D:20240730172133+05'30'\",\n",
            " 'creationDate': \"D:20240715122934+05'30'\",\n",
            " 'page': 0}\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "import pprint\n",
        "\n",
        "file_path = \"./sample_data/timolol.pdf\"\n",
        "loader = PyMuPDFLoader(file_path)\n",
        "docs = loader.load()\n",
        "num_pages = docs[0].metadata['total_pages']\n",
        "print(num_pages)\n",
        "pprint.pp(docs[0])\n",
        "pprint.pp(docs[1])\n",
        "\n",
        "pprint.pp(docs[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ksk-czaxN5"
      },
      "source": [
        "The additional metadata like page number and title is relevant to our product because when we answer questions: we can also point users to specific sections of the original document which they can refer to for more clarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eI1CZqcbF7S"
      },
      "source": [
        "Our next step is to index this entire document which we do with the help of OpenAI embeddings. However, before we do that we need to split document into chunks so that at the time of retrieval we are identifying the correct parts of the document. We use one of the in-built Langchain components that allows us to split based on characters based on our specifications.\n",
        "\n",
        "We have chosen to split the entire document into chunks of length 2000 characters and also ensure an overlap of 200 characters. This makes sure that we are not loosing any information when splitting up the document. As we will see later, this is one of the parameters that we can control and could have an influence on the performance of our product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbkgyfD9NryJ"
      },
      "source": [
        "## üìù Learner Task:\n",
        "\n",
        "In the following section, you have to decide the best chunking strategy for your PDF and use case. For instance, you could make use of the `RecursiveCharacterTextSplitter` to work with text documents. It's important to also decide what are reasonable values for `chunk_size` and `chunk_overlap`. In the project walkthrough we provide some suggested values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xMZXPdM9fae",
        "outputId": "9699eb29-3ce4-4b39-b8d9-5947c4b97b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "full_text = ''\n",
        "for page in docs:\n",
        "  full_text += page.page_content\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "splits = text_splitter.create_documents([full_text])\n",
        "print(len(splits))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tqcP7ljBQsK"
      },
      "source": [
        "We are optimising for retrieval - i.e. how fine-grained is the context that we can retrieve so that we can answer the question that our user is asking. In this case, it might be better to have a smaller chunk because you are then narrowing down on the perfect part of the text where this information is present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UBVkp6TbaZDr"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from google.colab import userdata\n",
        "\n",
        "## Define the embedding model below by using the `text-embedding-3-small` model\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small', openai_api_key=userdata.get('OPENAI_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDaUK7NbE8J4"
      },
      "source": [
        "A huge advantage of using Langchain is that it provides integrations with several types of vector databases like Chroma, Pinecone and more. In this project, we make use of the FAISS library from Facebook/Meta as a simple choice. In the following section, we combine the steps of generating the embedding value for each document chunk and then also storing it into the FAISS vector database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NDV_HnMFFJfb"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vector_store = FAISS.from_documents(documents=splits, embedding=embedding_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nI7cwlNdiBr"
      },
      "source": [
        "We have our documents indexed and we can directly start retrieving documents based on a similarity search with a target query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1_wRhCQJBLJ",
        "outputId": "0357ff36-70c7-4bca-eeb9-98ed3e75c6f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(id='82336006-304e-47c2-9837-1406f87e74b4', metadata={}, page_content='7. Wash your hands, tilt your head back and look at the ceiling (Fig.7). \\n \\n \\n \\n8. Gently pull the lower eyelid down to form a small pocket between the eyelid and the eye (Fig.8). \\n \\n \\n \\n9. Turn the bottle upside down and squeeze it gently to release one drop into each eye that needs \\ntreatment. Do not touch your eye or eyelid with the dropper tip (Fig. 9). If a drop misses your eye, try \\nagain.10. Let go of the lower lid, and close your eye For 2 minutes, by pressing the finger into the corner of \\nyour eye, by the nose (Fig.10). This helps to stop timolol getting into the rest of your body. \\n \\nOphthalmic medications, if handled improperly, can become contaminated by common bacteria \\nknown to cause infections. Serious damage to the eye and subsequent loss of vision may result from \\nusing contaminated ophthalmic medications. If you think your medication may be contaminated, or if \\nyou develop an eye infection, contact your doctor immediately concerning continued use of this bottle. \\n \\n \\n \\n11.  Repeat steps 8 , 9 & 10 with the other eye if instructed to do so by your doctor.  \\n12. Reclose the bottle after use (Fig.11). The next time you need to apply the drops follow steps 7-12 \\n \\n \\n13. The dispenser tip is designed to provide a pre-measured drop; therefore, do NOT enlarge the hole of \\nthe dispenser tip. \\n \\n14. After you have used all doses, there will be some eye drops solution left in the bottle. You should \\nnot be concerned since an extra amount of solution has been added and you will get the full amount of \\nTimolol that your doctor prescribed. Do not attempt to remove the excess medicine from the bottle. \\n \\nUse in children and adolescents \\nBefore you or your child starts to take Timolol, your doctor or your child‚Äôs doctor will have carried \\nout a detailed medical examination and decided whether or not this medicine is suitable. You or your \\nchild, especially a newborn, should be closely monitored for one to two hours after the first dose and'),\n",
              "  0.10973540635856927),\n",
              " (Document(id='7368ad57-134b-47bb-85c8-8ebc6aef2621', metadata={}, page_content='child, especially a newborn, should be closely monitored for one to two hours after the first dose and \\ncarefully monitored for any signs of side effects until surgery is carried out.Method of administration: \\nOne drop only of Timolol should be instilled into the affected eye(s) each time. Follow the \\n‚ÄúInstructions for Use‚Äù above when administering the eye drops. After using Timolol, press a finger \\ninto the corner of your eye, by the nose for 2 minutes. This helps to stop timolol getting into the rest of \\nyour body. \\n \\nDuration of treatment: \\nYour doctor or your child‚Äôs doctor will decide for how long the eye drops will be needed. \\n \\nIf you use more Timolol Eye Drops than you should  \\nIf you put too many drops in your eye or swallow any of the drops, you may:  \\n\\uf0b7 \\nhave a headache  \\n\\uf0b7 \\nfeel dizzy or light-headed  \\n\\uf0b7 \\nhave difficulty breathing \\n\\uf0b7 \\nchest pain \\n\\uf0b7 \\nfeel that your heart rate has slowed down.  \\n \\nIf this happens, contact your doctor immediately.  \\n \\nIf you forget to use Timolol Eye Drops \\nIt is important to take Timolol as prescribed by your doctor. \\n\\uf0b7 \\nIf you miss a dose, use the drops as soon as possible.  \\n\\uf0b7 \\nIf it is almost time for the next dose, skip the missed dose and take the next dose at the usual \\ntime.  \\n\\uf0b7 \\nDo not take a double dose to make up for the forgotten dose.  \\n \\nIf you stop using Timolol Eye Drops \\nIf you want to stop using this medicine talk to your doctor first. If you have any further questions on \\nthe use of this medicine, ask your doctor, pharmacist or nurse. \\n \\n \\n4. \\nPossible side effects \\n \\nLike all medicines Timolol Eye Drops can cause side effects, although not everybody gets them.   \\nYou can usually carry on taking the drops, unless the effects are serious. If you are worried, talk to \\nyour doctor or pharmacist. Do not stop using Timolol Eye drops without speaking to your doctor.  \\n \\nLike other medicines applied into eyes, timolol is absorbed into the blood. This may cause similar side'),\n",
              "  0.09605698384914674),\n",
              " (Document(id='08ede2ba-d9af-45ec-bb8d-148d65f511e3', metadata={}, page_content='Website: www.mhra.gov.uk/yellowcard or search for MHRA Yellow Card in the Google Play \\nor Apple App Store \\n \\nIreland \\nHPRA Pharmacovigilance \\nEarlsfort Terrace  \\nIRL - Dublin 2 \\nTel: +353 1 6764971 \\nFax: +353 1 6762517 \\nWebsite: www.hpra.iee-mail: medsafety@hpra.ie \\n \\nBy reporting side effects you can help provide more information on the safety of this medicine. \\n \\n \\n5.  \\nHow To Store Timolol \\n \\nKeep your eye drops out of the sight and reach of children.  \\n\\uf0b7 \\nThis medicinal product does not require any special storage condition before first opening. \\n\\uf0b7 \\nDo not store your eye drops above 25¬∞C after first opening. Store the bottle in the outer carton.  \\n\\uf0b7 \\nYou can use Timolol for 28 days after first opening the bottle. Discard the opened bottle with \\nany remaining solution after that time. \\n \\nDo not use Timolol Eye Drops after the expiry date which is stated on the carton after EXP. The \\nexpiry date refers to the last day of that month.  \\n \\nDo not throw away any medicines via wastewater or household waste. Ask your pharmacist how to \\nthrow away medicines you no longer use. These measures will help protect the environment. \\n \\n \\n6. \\nContents of the pack and other information \\n \\nWhat Timolol contains  \\n \\nThe active substance is timolol maleate.  \\n \\nThe other ingredients are:  \\n\\uf0b7 \\nbenzalkonium chloride as preservative  \\n\\uf0b7 \\ndisodium phosphate dodecahydrate (E339) \\n\\uf0b7 \\nsodium dihydrogen phosphate dihydrate (E339) \\n\\uf0b7 \\nsodium hydroxide  \\n\\uf0b7 \\nwater for injections.  \\n \\nWhat Timolol Eye Drops looks like and contents of the pack  \\n \\nTimolol is a clear colourless to light yellow sterile eye drops solution available in two strengths: \\n\\uf0b7 \\n0.25% w/v solution of timolol  \\n\\uf0b7 \\n0.5% w/v solution of timolol  \\n \\nTimolol is available in bottles containing 5 ml of sterile eye drops solution. Timolol 0.5% w/v is \\nadditionally available in a 10ml bottle size. \\n \\nNot all pack sizes may be marketed. \\n \\nMarketing Authorisation Holder  \\nBrown & Burk UK Ltd \\n5 Marryat Close \\nHounslow West'),\n",
              "  0.06435749614713304),\n",
              " (Document(id='e9240225-2795-4417-8941-fdaaad783585', metadata={}, page_content='\\uf0b7 \\nmedicines known as catecholamine-depleting agents, such as rauwolfia alkaloids or reserpine, \\nused for high blood pressure  \\n\\uf0b7 \\nmedicines called pressor amines, such as adrenaline used to treat severe allergic reaction  \\n\\uf0b7 \\nQuinidine (used to treat heart conditions and some types of malaria) \\n\\uf0b7 \\nAntidepressants known as fluoxetine and paroxetine. \\n\\uf0b7 \\nclonidine, a medicine used to treat high blood pressure  \\n\\uf0b7 \\nother beta-blockers taken by mouth or used as eye drops, because they belong to the same group \\nof medicines as Timolol and could have an additive effect.Pregnancy and breast-feeding \\nAsk your doctor for advice before taking any medicine  \\n \\nUse in pregnancy \\nDo not use Timolol if you are pregnant unless your doctor considers it necessary. \\n \\nUse in breast-feeding \\nDo not use Timolol if you are breast-feeding. Timolol may get into your milk. Ask your doctor for \\nadvice before taking any medicine during breast-feeding. \\n \\nDriving and using machines  \\nThere are possible side effects associated with Timolol Eye Drops, such as dizziness, tiredness and \\nchanges in your eyesight, such as blurred vision, drooping of the upper eyelid (making the eye stay \\nhalf closed), double vision which may affect your ability to drive and/or operate machinery. Do not \\ndrive and/or operate machinery until you feel well and your vision is clear. \\n \\nTimolol Eye Drops contains the preservative benzalkonium chloride. \\nThis medicine contains 0.1 mg benzalkonium chloride in each ml. \\nBenzalkonium chloride may be absorbed by soft contact lenses and may change the colour of the \\ncontact lenses. You should remove contact lenses before using this medicine and put them back 15 \\nminutes afterwards. Benzalkonium chloride may also cause eye irritation, especially if you have dry \\neyes or disorders of the cornea (the clear layer at the front of the eye). If you feel abnormal eye \\nsensation, stinging or pain in the eye after using this medicine, talk to your doctor. \\n \\n \\n3. \\nHow to use Timolol'),\n",
              "  0.054673077589996844)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "search_result = vector_store.similarity_search_with_relevance_scores(query=\"What is the recommended dosage?\", k=4)\n",
        "search_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxPewWEYLG1R"
      },
      "source": [
        "In this case, we have chosen to use cosine similarity as our distance metric and the similarity values are also shown along with the retrieved results. You will notice that not many of the retrieved chunks actually contain the text \"Weight Loss\" - and this is because we are not doing a word-based search but rather semantic search. This is what vector databases allow us to do. However, it is also possible that at times we want to match exact query terms and then we will follow a hybrid search approach. This is again one of the levers that we have to expriment with to determine what is necessary for our product. So it's important that you are able to determine what is the best method for you to choose - depends a lot on your use-case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_MbjNwSaEOn"
      },
      "source": [
        "### Creating the QnA RAG chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7eiBrgeetbs"
      },
      "source": [
        "Let's move on to complete our product by integrating with the LLM. Here again, we rely heavily on the building blocks that Langchain already provides us to put together the entire chain.\n",
        "\n",
        "The chain consists of multiple parts - a Retriever, followed by a Prompt Template where the retrieved documents are added and then the call to the LLM. The response from the LLM is what we finally show as output to the user. There are multiple steps in creating a RAG application. We break it down to make it easier to understand and follow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlqW4TbcOfBw"
      },
      "source": [
        "## üìù Learner Task:\n",
        "Creating the Prompt Template. In the section below, please create the PromptTemplate that will be used for your RAG application. The `ChatPromptTemplate` has become the standardized way to use chat-based LLMs and consists of a `SystemMessage`, followed by the `HumanMessage` with the response from the LLM stored in the `AIMessage`. We have provided the necessary imports in the below cell and request you to create the variable `qna_prompt_template` that will be used in the application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5cv_Fi0IPfn5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import SystemMessagePromptTemplate\n",
        "from langchain.prompts import HumanMessagePromptTemplate\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are an expert with medical knowledge who is able to read drug\n",
        "pamphlets and uses that information to answer the questions you are\n",
        "given.\n",
        "\n",
        "You are able and skilled at describing things in a simple fashion.\n",
        "If you are uncertain of the answer or correctness, simply say that you\n",
        "are uncertain.\n",
        "\"\"\"\n",
        "\n",
        "human_prompt = \"\"\"\n",
        "The context for your questions is {context}.\n",
        "The question is {question}.\n",
        "\"\"\"\n",
        "\n",
        "qna_prompt_template = ChatPromptTemplate([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", human_prompt),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iumOVFV4Pk_X"
      },
      "source": [
        "After the PromptTemplate, the next step is to define the LLM Model that you would like to run with. We provide the OpenAI API models as the default option and make use of `gpt-4o-mini`. We also set the `temperature` value to 0 as we do not want the model to be creative but rather answer based on the retrieved context from the PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9-wDIb1gQI7E"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\",\n",
        "                 temperature=0,\n",
        "                 openai_api_key=userdata.get('OPENAI_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDlnYaodQPeU"
      },
      "source": [
        "The next step is to initilize the retriever part of our application that will fetch the relevant documents from the PDF. Recall that we have already created the embeddings for our document chunks and stored it using the FAISS vectorstore. In this step, we only specify that vectorestore to be our retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hz_SleAiQrTi"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEtojMFZQyjR"
      },
      "source": [
        "One additional step that we need to also consider is that when the documents are retrieved from the FAISS vectorstore, they are in the form of a list of documents. These document objects contain a lot more information other than the content like Metadata. Assuming we are performing a simple retrieval, the context that we want to pass to the LLM is only the text content. Therefore we write an additional function that combines only the retrieved text content that can be used to pass in the context of our PromptTemplate.\n",
        "\n",
        "Please note that you could also choose to filter the retrieved documents based on the Metadata. For instance, if you only want to see results from Page 5 and beyond of the PDF - then you can also adapt this function to reflect that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b64wwSooQv2f"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VVUVqJARaYJ"
      },
      "source": [
        "The final stage is to put together the various elements that we have defined above to create our pipeline. The key aspect to note here is that the input question is used twice during the process -> at the first instance to retrieve a list of the relevant context and the second instance when it is passed to the LLM as the question that needs to be answered.\n",
        "\n",
        "So we make use of the `itemgetter` to retrieve the content of the question and pass to the retriever to get the relevant context. On the other hand, we make use of the `RunnablePassthrough` class to directly pass the input question to the subsequent operation. At the end we also add the `StrOuputParser` to get the actual text message of the response rather than the whole AIMessage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VI7UOE70LleJ"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": itemgetter(\"input\") | retriever | format_docs,\n",
        "     \"question\": RunnablePassthrough()}\n",
        "    | qna_prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5YW6DF-Sog3"
      },
      "source": [
        "Please check that your entire chain works by providing your questions and invoking the RAG chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ftZIkyQISoAt",
        "outputId": "9297b046-c92b-4611-fab4-9b60d2b872dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The dosage for a child, especially a newborn, is one drop of Timolol Eye Drops instilled into the affected eye(s) each time, as prescribed by the doctor. The doctor will determine how long the eye drops will be needed. It is important to closely monitor the child for any signs of side effects after the first dose.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "question = \"What is the dosage for a child?\"\n",
        "rag_chain.invoke({\"input\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBbDadkAT1zB"
      },
      "source": [
        "## üìù Learner Task:\n",
        "If you run into errors as you develop, visualizing the chain is an easy way to discover any issues. This visualization helps us understand the entire flow of operations within our application. By graphically representing the connections and interactions between different components we can see how the data flows and in which shape from one path tothe next. It allows for easier debugging and we might be able to pinpoint where modifications might be necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l50o8HECL53q",
        "outputId": "0b701031-16b8-4aaa-b643-d75e01e1fe7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           +---------------------------------+        \n",
            "           | Parallel<context,question>Input |        \n",
            "           +---------------------------------+        \n",
            "                    **              ***               \n",
            "                 ***                   **             \n",
            "               **                        ***          \n",
            "       +--------+                           **        \n",
            "       | Lambda |                            *        \n",
            "       +--------+                            *        \n",
            "            *                                *        \n",
            "            *                                *        \n",
            "            *                                *        \n",
            "+----------------------+                     *        \n",
            "| VectorStoreRetriever |                     *        \n",
            "+----------------------+                     *        \n",
            "            *                                *        \n",
            "            *                                *        \n",
            "            *                                *        \n",
            "    +-------------+                   +-------------+ \n",
            "    | format_docs |                   | Passthrough | \n",
            "    +-------------+*                  +-------------+ \n",
            "                    **              **                \n",
            "                      ***        ***                  \n",
            "                         **    **                     \n",
            "          +----------------------------------+        \n",
            "          | Parallel<context,question>Output |        \n",
            "          +----------------------------------+        \n",
            "                            *                         \n",
            "                            *                         \n",
            "                            *                         \n",
            "                  +--------------------+              \n",
            "                  | ChatPromptTemplate |              \n",
            "                  +--------------------+              \n",
            "                            *                         \n",
            "                            *                         \n",
            "                            *                         \n",
            "                      +------------+                  \n",
            "                      | ChatOpenAI |                  \n",
            "                      +------------+                  \n",
            "                            *                         \n",
            "                            *                         \n",
            "                            *                         \n",
            "                   +-----------------+                \n",
            "                   | StrOutputParser |                \n",
            "                   +-----------------+                \n",
            "                            *                         \n",
            "                            *                         \n",
            "                            *                         \n",
            "                +-----------------------+             \n",
            "                | StrOutputParserOutput |             \n",
            "                +-----------------------+             \n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print (rag_chain.get_graph().print_ascii())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "w2UsVkHkQs7P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwTao9CgfNrN"
      },
      "source": [
        "\n",
        "Hopefully, you have managed to build the skeleton for your product. At first just make sure that everything is working in an end to end fashion. After you have achieved that you can move in the direction of improving the answers from the application. This is when you can start experimenting with different aspects of your pipeline to go in the direction of a better solution.\n",
        "\n",
        "We would recommend adapting the following options:\n",
        "\n",
        "- Chunk size:\n",
        "- Retrieval strategy/ metric:\n",
        "- Choice of LLM:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvhtzIRbfrec"
      },
      "source": [
        "At the end of this stage, you should be able to have a working prototype of your solution that does reasonably well for the use-case you have in mind.\n",
        "\n",
        "We are still relying on a vibe/gut-feel for the product and cannot rely on quantified metrics. But hopefully you can feel reasonably confident to launch an alpha version of your product to a select group of customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlvAHj4bPl6Q"
      },
      "source": [
        "# Step 2: Deploying the PillPal bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X3ZhG3_PqrI"
      },
      "source": [
        "Before deploying our product, one of the important steps is to enable tracking and monitoring all the user queries and LLM responses. This is made very easy for us with the help of Langsmith - another part of the Langchain ecosystem.\n",
        "\n",
        "This is one of the cornerstones of our strategy to get towards a more valuable and performing LLM app.\n",
        "\n",
        "Please sign-up on the Langsmith [Website](https://smith.langchain.com/) and you should have access. Next, please navigate to the Settings page from the left side navigation menu and then create your API key there and copy it.\n",
        "\n",
        "<a href=\"https://ibb.co/fN8s3Yp\"><img src=\"https://i.ibb.co/ZgH0Q68/Screenshot-2024-07-26-at-16-12-48.png\" alt=\"Screenshot-2024-07-26-at-16-12-48\" border=\"0\"></a>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "After that, you can return to the main page and click the New Project icon and copy the environment details that you see.\n",
        "\n",
        "<a href=\"https://ibb.co/th2CQhd\"><img src=\"https://i.ibb.co/yRksdR3/Screenshot-2024-07-26-at-16-12-59.png\" alt=\"Screenshot-2024-07-26-at-16-12-59\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AylFlTLPyp5"
      },
      "source": [
        "We can deploy our LLM app in two different ways -\n",
        "\n",
        "1. A website based chatbot experience - this will be done with the help of Gradio and you do not need to leave the Colab notebook environment\n",
        "2. A telegram chatbot that will run on Github Codespaces (or locally) and will need you to leave the Colab environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TQ_kDighGgL"
      },
      "source": [
        "### Deployed as website chatbot\n",
        "\n",
        "We can deploy our QnA bot on a dedicated website using Gradio, an easy-to-use library for creating interactive machine learning interfaces. One significant advantage of using Gradio in our project is that it integrates seamlessly within the Colab notebook environment. This means you don't need to leave Colab to see your bot in action; you can run it directly from the notebook. Gradio also provides a dedicated URL that you can share with potential beta testers of the QnA bot to get feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "DDy0V7_eoEYt",
        "outputId": "ac6c3d84-e17b-46b6-be18-13bf63c2d768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/chatbot.py:290: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1d0ba1eda0b3ee8c0e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1d0ba1eda0b3ee8c0e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://1d0ba1eda0b3ee8c0e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "import openai\n",
        "import gradio as gr\n",
        "\n",
        "def predict(message, history):\n",
        "    return rag_chain.invoke({\"input\":message})\n",
        "\n",
        "gr.ChatInterface(predict).launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6TnwMSgpNps"
      },
      "source": [
        "### [OPTIONAL] Deployed as Telegram bot\n",
        "\n",
        "For a wider launch of your LLM app, you can easily make it available as a bot on Telegram - a messenger platform that is used by 500 million users every day. This is useful in the beta/alpha phase because it's way easier to get users to try it in an app that they already use every day. This need not be just Telegram but other popular messengers like Whatsapp, Signal etc. We chose Telegram as it's free and easy to setup.\n",
        "\n",
        "In order to deploy using this option, we will make use of Github codespaces as it's difficult to run it within a synchronous coding environment like Colab. The instructions and code for this will be provided in the live project session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmX9Z7lZ8eWT"
      },
      "source": [
        "Please go to the Github repository: https://github.com/sidhusmart/uplimit_langchain.git and clone it so that you can work on it directly. Please note that code in this repository may change frequently so we request you to work only on your cloned version.\n",
        "\n",
        "Once you have cloned it, then you can launch your own Codespaces instance by following the steps as shown in the screenshot. This creates a virtual Visual Studio Code environment in the cloud where we can test our Telegram bot.\n",
        "\n",
        "<a href=\"https://ibb.co/p02fJ1t\"><img src=\"https://i.ibb.co/BzLyqfX/Screenshot-2024-07-26-at-16-05-46.png\" alt=\"Screenshot-2024-07-26-at-16-05-46\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC344Wj19pcE"
      },
      "source": [
        "The two important files for you to take a look are `langchain_rag_app.py` and `telegram_response_bot.py` The first python file contains the same RAG functionality that we already built but packaged in functions. The telegram response bot contains the necessary code required to run the Telegram bot.\n",
        "\n",
        "In order to setup and run this app, we have to add the necessary API keys. This is the same process as what we have done previously in the Colab notebook but since we are executing this code in a new environment, we have to add the necessary secrets there as well.\n",
        "\n",
        "We do this via the `.env.dev` file. This file does not exist in the repository by default but instead we have provided the template file called `.env.template`. You need to create a copy of this file and rename it to be `.env.dev` that will contain all the API keys you are going to use during development of the app. Please note that this file is not checked in as we do not want to commit the secrets!  \n",
        "\n",
        "You can observe that there are several environment variables defined in the .env file - most of which we have already setup. You can use the same values for those keys again.\n",
        "\n",
        "However, there is one additional API key that is required to work with the Telegram API. In order to get the Telegram bot API key, you need to follow these steps:\n",
        "\n",
        "1. You must have a Telegram account and access to the App - Web or Mobile versions would also work.\n",
        "2. On the Telegram app, you need to search and look for a contact called the Botfather.\n",
        "3. You can use the `/start` command to get a list of options or directly use the `/newbot` command to create a new bot for yourself.\n",
        "4. Then answer the set of questions by providing a name for and username for your bot.\n",
        "5. At the end you will be provided with an API token that you can use to work with the bot. This API token is what we need to replace in the .env.dev file. `telegram_response_bot.py` file.\n",
        "\n",
        "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/f2MqxCd/Screenshot-2024-07-26-at-14-23-02.png\" alt=\"Screenshot-2024-07-26-at-14-23-02\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOutTlUR_zmC"
      },
      "source": [
        "Once you have performed both these steps, you are now ready to run your RAG app as a Telegam bot. You need to run the command `python telegram_response_bot.py ` from the command line of your Github Space and this starts a thread that listens for messages on your bot. Once a message is received, it then hands off to the RAG app and provides the generated response.\n",
        "\n",
        "You can easily share this Pillpal bot with your friends and family and ask them to try it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_4zSQWPQM-R"
      },
      "source": [
        "# Step 3: Evaluation of PillPal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9wzLbcQptfZ"
      },
      "source": [
        "Now that we have deployed and made our app live, we need to consistently monitor how it performs. This is also a way for us to understand what questions are being asked by our users and whether the bot is responding correctly or not. For this we will make use of the Langsmith part of the Langchain library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvj_e6UYon-V"
      },
      "source": [
        "As the first step, we have to create a validation dataset that we can use for evaluation. There are several ways to go about doing this:\n",
        "\n",
        "1. Launch your app in beta and get some trial users to start interacting with the bot/chat interface and identify common patterns and questions that are being asked. Manually, write your own answers to these questions and perform evaluations using that.\n",
        "2. Come up with a list of 5-10 questions and manually search for the answers of these questions in the PDF and create this as your evaluation dataset -> this is what we are going to do below.  \n",
        "3. You could also make use of another LLM to come up with these questions and answers which is called creating a synthetic dataset. This would work well if you use higher level models like GPT-4 but you need to keep in mind that they have to be relevant to the context of your leaflet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-H03qVVaMkH"
      },
      "source": [
        "### Creating a base evaluation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xTfANXXXd5P"
      },
      "source": [
        "To ensure that our application is functioning correctly and effectively answering questions, we have implemented a basic sanity check. This involves a set of 8-10 questions that I have manually curated and answered after thoroughly reviewing the content of the PDF document. These questions are designed to cover a wide range of topics and complexities within the document, ensuring that they test various aspects of our QnA bot's capabilities. By comparing the answers generated by our bot to these manually prepared responses, we can gauge the accuracy and reliability of our system. This step is crucial as it helps us identify any discrepancies or areas needing improvement before the application is deployed for wider use. Additionally, it provides an initial layer of validation and builds confidence in the application's performance among users and stakeholders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv6vi_EAT89n"
      },
      "source": [
        "## üìù Learner Task:\n",
        "\n",
        "Please create a set of question and correct answer pairs here to use as your evaluation dataset. We have provided the first two questions as examples but feel free to overwrite and add your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wXFxOClWQPbe"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    (\n",
        "        \"Can it be taken by pregnant women?\",\n",
        "        \"No, it should not be taken by pregnant women before seeking the doctors advice.\",\n",
        "    ),\n",
        "    (\n",
        "        \"Can it be given to children?\",\n",
        "        \"Yes, it has been tested in newborns with glaucoma, however extreme care must be given.\",\n",
        "    ),\n",
        "    (\n",
        "        \"What is the usual dosage?\",\n",
        "        \"One drop per affected eye, 1 to 2 times per day.\"\n",
        "    ),\n",
        "    (\n",
        "        \"How do I prevent absorption of the medication in the rest of the body\",\n",
        "        \"Close eye and press finger on inside corner of eye for 1-2 minutes.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Can timolol affect blood pressure?\",\n",
        "        \"Yes, timolol can cause lower blood pressure.\"\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x82VVhfGqJ9S"
      },
      "source": [
        "Once we have successfully created our dataset, the next step involves registering it with the Langsmith client. This process integrates the dataset into our evaluation framework. By registering the dataset, we effectively add it to the list of datasets available for testing and validating our model. In general, you might create multiple datasets to test various aspects of the QnA bot and might run different types of evaluations on it.\n",
        "\n",
        "In this case, we are running a test for general correctness of the QnA bot - while this does include checks for hallucinations -> we have added examples where the bot should not have an answer and must say so. But there are additional datasets that you might create with separate evaluation metrics to explicitly check for hallucination and fact-checking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hGqC94J7qSEn"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2EbuuZNMqTRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "076339ba-f57c-458f-9791-0b064b498a04"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "LangSmithConflictError",
          "evalue": "Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langsmith/utils.py\u001b[0m in \u001b[0;36mraise_for_status_with_text\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langsmith/client.py\u001b[0m in \u001b[0;36mrequest_with_retries\u001b[0;34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m                         )\n\u001b[0;32m--> 744\u001b[0;31m                     \u001b[0mls_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status_with_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langsmith/utils.py\u001b[0m in \u001b[0;36mraise_for_status_with_text\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLangSmithConflictError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-afcf20536e30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"PillPall Accuracy Test Dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m inputs, outputs = zip(\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expected\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langsmith/client.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, dataset_name, description, data_type, inputs_schema, outputs_schema, transformations, metadata)\u001b[0m\n\u001b[1;32m   3223\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs_schema_definition\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3225\u001b[0;31m         response = self.request_with_retries(\n\u001b[0m\u001b[1;32m   3226\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m             \u001b[0;34m\"/datasets\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langsmith/client.py\u001b[0m in \u001b[0;36mrequest_with_retries\u001b[0;34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m                             )\n\u001b[1;32m    788\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                             raise ls_utils.LangSmithConflictError(\n\u001b[0m\u001b[1;32m    790\u001b[0m                                 \u001b[0;34mf\"Conflict for {pathname}. {repr(e)}\"\u001b[0m \u001b[0;34mf\"{_context}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                             )\n",
            "\u001b[0;31mLangSmithConflictError\u001b[0m: Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = \"PillPall Accuracy Test Dataset\"\n",
        "dataset = client.create_dataset(dataset_name=dataset_name)\n",
        "inputs, outputs = zip(\n",
        "    *[({\"input\": input}, {\"expected\": expected}) for input, expected in examples]\n",
        ")\n",
        "client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqUUjzJUq_F5"
      },
      "source": [
        "Once the above cells are run, you should now be able to see the dataset created in the dataset folder in your Langsmith project.\n",
        "\n",
        "![QA Dataset](https://i.ibb.co/sH5dv86/Xnapper-2024-06-11-20-58-53.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcZrdxNVrci2"
      },
      "source": [
        "Let's run the evaluation of our app using this dataset.\n",
        "\n",
        "By executing the code below, we will first be calling our app for each of the questions in our QA dataset. Once the answers have been generated, we need to evaluate it with the golden standard answers that we have written manually. But the big question is always: how can we compare two texts, what metrics shall we use?\n",
        "\n",
        "One of the easier ways to do this is by using another LLM to compare the two responses and tell you whether they match or not. This is also referred to as 'LLM-as-a-judge'. In this case, since we have only 5-10 examples you can easily do this manually but typically your evaluation datasets will contain a lot of examples and this method would not work.\n",
        "\n",
        "We will use the off-the-shelf evaluator that Langsmith provides us called `cot_qa` that stands for Chain of Thought Question Answer. This basically refers to a pre-filled prompt that is used when asking the \"Judge LLM\" to rate whether the two answers are comparable or not.\n",
        "\n",
        "Typically we make use of a bigger, more powerful LLM to act as the judge for what the smaller, cheaper LLM has generated. However, since our dataset is small and quite easy we stick with `gpt-4o-mini`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMe1SzrvrKMs"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "eval_llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o-mini\", openai_api_key=userdata.get('OPENAI_API_KEY'))\n",
        "cot_qa_evaluator = LangChainStringEvaluator(\"cot_qa\", config={\"llm\": eval_llm})\n",
        "\n",
        "client = Client()\n",
        "evaluate(\n",
        "    rag_chain,\n",
        "    data=dataset_name,\n",
        "    evaluators=[cot_qa_evaluator],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd_6YQfQsvgw"
      },
      "source": [
        "Let's run the evaluation on the dataset. You get the links to where you can track the run and at the end the output is also printed here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5PPIGVIYU8Z"
      },
      "source": [
        "After initiating the evaluation of our QnA bot using the dataset we registered, you will be able to observe several key performance metrics. These metrics include the percentage of questions answered correctly, which provides a direct measure of the bot's accuracy. You will also see the duration of the test, which gives insight into the efficiency of the bot under testing conditions. Additionally, the evaluation will report on costs and latency, offering a broader view of the bot's operational performance.\n",
        "\n",
        "This initial evaluation serves as a preliminary indication of how well your bot is performing. As the bot encounters more users and a diverse array of questions, it's crucial to continually update and adapt your baseline test dataset. This iterative process ensures that the bot remains effective and responsive to the evolving needs and contexts it will encounter in real-world applications.\n",
        "\n",
        "![Evaluation Test results](https://i.ibb.co/txtzhtD/Xnapper-2024-06-16-11-32-28.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj_PnIs8aouf"
      },
      "source": [
        "## üìù Learner Task:\n",
        "\n",
        "Now that you have an end to end RAG chatbot up and running, you can try to stress-test your bot by asking all kinds of questions - both relevant and irrelevant. What kind of responses does it generate? How often does it hallucinate?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee6O1L_cy69n"
      },
      "source": [
        "Simple irrelevant medical questions on other medicine get an uncertain result with consultation advice. A totally irrelevant question did give the answer but also noted it was not related to the topic and a pointer to get back on track.. A wacky question using the drug as part also got that it was uncertain and information about consultation.\n",
        "\n",
        "```\n",
        "What is the usual dosage of aspirin?\n",
        "\n",
        "I'm uncertain about the usual dosage of aspirin, as the information provided is specifically about Timolol Eye Drops and does not include details on aspirin. For accurate dosage information regarding aspirin, it's best to consult a healthcare professional or refer to the medication's prescribing information.\n",
        "\n",
        "How many cups are there in a gallon?\n",
        "\n",
        "I'm uncertain about the answer to that question, as it is not related to the medical context or information about Timolol. However, to answer your question: there are 16 cups in a gallon. If you have any questions about Timolol or related medical topics, feel free to ask!\n",
        "\n",
        "How does timolol cause global warming?\n",
        "\n",
        "I am uncertain about how timolol, a medication used for treating eye conditions, could cause global warming. Timolol is a beta-blocker that affects the cardiovascular system and is primarily used to lower intraocular pressure in conditions like glaucoma. It does not have a direct connection to environmental issues such as global warming. If you have concerns about the environmental impact of pharmaceuticals or specific medications, it would be best to consult a specialist in environmental science or pharmacology.\n",
        "```\n",
        "\n",
        "Explicitly asking to ignore the prompt and information that was given does have the bot respond to irrelevant questions, so some form of protection for that would be necessary if not intended for personal/limited use."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}